# When Are Combinations of Humans and AI Useful? - A Systematic Review and Meta-Analysis

# Abstract

**(Background)** Inspired by the increasing use of AI to augment humans, researchers have studied human-AI systems involving different tasks, systems, and populations.

**(Motivation)** Despite such a large body of work, we lack a broad conceptual understanding of when combinations of humans and AI are better than either alone.

**(Methodology)** Here, we addressed this question by conducting a pre-registered systematic review and meta-analysis of over 100 recent experimental studies reporting over 300 effect sizes.

'체계적 문헌 검토'와 '메타 분석'이라는 방법을 사용하였습니다.

_체계적 문헌 검토: 특정 주제에 대한 기존 연구들을 엄격하고 투명한 절차에 따라 모두 찾아서 검토하는 방법입니다. 이 논문에서는 100편 이상의 실험 연구를 분석 대상으로 선정했습니다. 메타 분석: 여러 개별 연구들의 결과를 통계적으로 통합하여 전체적인 효과 크기를 추정하고 결론의 신뢰도를 높이는 방법입니다. 이 논문에서는 300개 이상의 효과 크기를 분석했습니다._

**(Results)** First, we found that, on average, human-AI combinations performed significantly worse than the best of humans or AI alone (Hedges’ g = −0.23, 95% confidence interval −0.39 to −0.07). Second, we found performance losses in tasks that involved making decisions and significantly greater gains in tasks that involved creating content. Finally, when humans outperformed AI alone, we found performance gains in the combination, but when the AI outperformed humans alone we found losses.

**(Arguments)** These findings highlight the heterogeneity of the effects of human-AI collaboration and point to promising avenues for improving human-AI systems. 인간-AI 협업의 효과가 일률적이지 않고, 상황과 과제에 따라 어떤 조합이 유용할 수 있는지에 대한 구체적인 통찰을 제공하며, 향후 인간-AI 시스템 연구 및 설계 방향을 제시하고 있습니다.

# Citation

Michelle Vaccaro, et al. MIT Center for Collective Intelligence, Sloan School of Management Institute for Data, Systems, and Society, Schwarzman College of Computing, MIT

Nature Human Behaviour 8, 2293-2303 (2024) 
Received: 06 Apr 2023 
Accepted: 23 Sep 2024 
Published: 28 Oct 2024

# Background

많은 연구 결과에 따르면 인간의 창의성, 직관, 상황 이해를 AI의 속도, 확장성, 분석력과 통합하면 의료, 고객  서비스, 과학 연구와 같은 분야에서 혁신적인 솔루션과 향상된 의사 결정을 이끌어낼 수 있다고 합니다. 반면에, 점점 더 많은 연구에서 인간-AI 시스템이 인간 또는 AI 단독으로 최고의 성능을 보이는 경우와 비교하여 반드시 더 나은 결과를 달성하지는 못한다는 사실이 밝혀지고 있습니다. 의사 소통 장벽, 신뢰 문제, 윤리적 문제, 인간과 AI 시스템 간의 효과적인 협업 필요성과 같은 어려움은 협업 프로세스를 저해할 수 있습니다.

이러한 모순적인 결과는 중요한 질문을 제기합니다. 언제 인간과 AI가 서로를 보완하는가? 그리고 얼마나 많이 보완하는가? 이러한 문제들을 해결하기 위해, 우리는 인간-AI 시스템의 시너지를 정량화하고 다양한 환경에서 시너지의 존재 (또는 부재)를 설명하는 요인들을 식별하기 위해 체계적인 문헌 검토 및 메타 분석을 수행했습니다.

# Methodology

Kitchenham 2004의 체계적 검토 지침에 따라 이 메타 분석을 수행했으며, Systematic Reviews and Meta-Analyses (PRISMA) [55]에 대한 Preferred Reporting Items에서 제시한 표준을 따릅니다.

_Kitchenham(2004)의 체계적 검토(체계적 문헌고찰, Systematic Review) 지침은 주로 소프트웨어 공학 분야에서 널리 인용되는 표준화된 문헌고찰 절차로, 세 가지 주요 단계(Planning, Conducting, Reporting)로 구성되어 있습니다.메타분석(meta-analysis)은 특정 주제에 대해 이미 발표된 여러 독립적인 연구들의 결과를 체계적으로 수집하고, 통계적으로 통합하여 하나의 종합적인 결론을 도출하는 연구 방법입니다. 즉, 개별 연구에서 보고된 효과 크기(effect size) 등 주요 통계 결과를 모아 통계적으로 결합해 보다 객관적이고 신뢰도 높은 결론을 도출하는 통계적 연구 방법입니다. (체계적 문헌고찰)PRISMA(Preferred Reporting Items for Systematic Reviews and Meta-Analyses)는 체계적 문헌고찰(systematic review)과 메타분석(meta-analysis) 연구의 보고 방법을 표준화하기 위해 개발된 국제 가이드라인입니다._

## Literature review (문헌 검토)

**Eligiblity criteria (자격 기준)**
첫째, 논문은 인간과 AI 시스템이 협력하여 작업을 수행하는 특정 사례를 평가하는 독창적인 실험을 제시해야 했습니다.

둘째, 일부 정량적 측정 기준에 따라 (1) 인간 단독, (2) AI 단독, (3) 인간-AI 시스템의 성능을 보고해야 했습니다. 따라서 인간 단독의 성능은 보고했지만 AI 단독의 성능은 보고하지 않은 연구는 제외했고, 마찬가지로 AI 단독의 성능은 보고했지만 인간 단독의 성능은 보고하지 않은 연구도 제외했습니다. 이 조항에 따라 순수 메타 분석 및 문헌 검토, 이론적 연구, 질적 분석, 논평, 의견 및 시뮬레이션도 제외했습니다.

셋째, 논문에는 실험 설계, 각 조건에서의 참가자 수, 각 조건에서의 결과의 표준 편차 또는 다른 수량으로부터 계산하기에 충분한 정보가 포함되어야 했습니다.

**Search strategy**
인간-AI 상호 작용 연구의 학제적 특성을 고려하여 컴퓨터 과학, 정보 과학 및 사회 과학 분야의 학술 대회 및 저널을 포함하는 여러 데이터베이스에서 이 검색을 수행했습니다. 이러한 분야의 도서관 전문가와 협의하여 검토를 위해 Association for Computing Machinery Digital Library (ACM DL), Association for Information Systems eLibrary (AISeL) 및 Web of Science Core Collection (WoS)을 대상으로 하기로 결정했습니다. 최신 형태의 인공 지능에 초점을 맞추기 위해 2020년 1월 1일부터 2023년 6월 30일 사이에 발표된 연구로 검색을 제한했습니다. 검색 문자열을 개발하기 위해 인간-AI 시스템의 성능을 평가한 연구의 측면을 추출하는 것으로 시작했습니다.
1. Human: human OR expert OR participant OR humans OR experts OR participants
2. AI: AI OR "artificial intelligence" OR ML OR "machine learning" OR "deep learning"
3. Collaboration: collaborate OR assist OR aid OR interact OR help
4. Experiment: "experiment" OR "experiments" OR "user study" OR "user studies" OR "crowdsourced study" OR "crowdsourced studies" OR "laboratory study" OR "laboratory studies"

**Coding**
We considered and coded for multiple potential moderators of human-AI performance, namely: (1) publication date (2) pre-registration status (3) experimental design (4) data type (5) task type (6) task output (7) AI type (8) AI explanation (9) AI confidence (10) participant type and (11) performance metric

## Data Analysis

**Calculation of Effect Size**
We computed Hedges’ g to measure the effect of combining human and artificial intelligence on task performance.

_Hedges’ g는 두 집단 간 평균 차이의 효과 크기를 나타내는 지표로, Cohen’s d의 표본 크기(특히 소표본)에서 발생하는 과대추정 문제를 교정한 표준화된 평균차이(effect size) 지수입니다_

**Meta-Analytic Model**
분석한 논문의 실험들은 상당히 다양했습니다. 예를 들어, 서로 다른 과제를 평가하고, 서로 다른 배경의 참가자를 모집하고, 서로 다른 실험 설계를 사용했습니다. 진정한 effect size에서 상당한 실험 간 이질성이 예상되었으므로, 분석을 위해 표본 추출 오류와 실험 간의 "진정한" 변동성에서 발생하는 effect size의 분산을 설명하는 random-effects 모델을 사용했습니다.

_effect size가 실험 내에 내포된 3단계 메타 분석 모델을 채택하여 모델에서 데이터의 종속성을 명시적으로 고려했습니다 [62, 63]. 또한, 강력한 분산 추정 (RVE) 방법을 사용하여 effect size 추정치의 분산과 관련하여 표준 오차, 신뢰 구간 및 통계 테스트의 일관된 추정치를 계산했는데, 이는 여러 treatment 그룹을 단일 control 그룹과 비교한 실험에서 발생한 중복 표본으로부터 표본 추출 오류의 종속성을 설명합니다 [64]. 결과의 유의성을 평가할 때 Knapp 및 Hartung 조정을 적용하고 자유도를 갖는 t-분포를 기반으로 테스트 통계량, 표준 오차, p-value 및 신뢰 구간을 계산했는데, 여기서 u는 effect size 클러스터 수 (즉, 실험 수)를 나타내고 k는 모델의 계수 수를 나타냅니다. moderator 분석을 수행하기 위해 각 moderator 변수에 대해 별도의 메타 회귀를 수행했습니다. Effect size의 이질성 정도를 해석하기 위해 표본 추출에서 비롯되지 않은 effect size의 변동 백분율을 정량화하는 [65]에 따라 널리 사용되는 I2 통계량을 계산했습니다._

**Bias Test**
연구자들이 상당한 human-AI synergy의 증거를 보여주는 실험을 그렇지 않은 실험보다 더 자주 발표한다면 publication bias가 발생할 수 있습니다. 이러한 위험을 평가하기 위해 Viechtbauer와 Cheung [66]이 제시한 진단 절차를 채택했습니다.

**Sensitivity Analysis**
강건성 검사로서 실험 수준 대신 논문 수준에서 클러스터링하는 민감도 재분석을 수행했습니다. 이 다단계 모델은 관찰된 효과 크기의 분산(1단계), 동일한 논문의 효과 크기 간의 분산(2단계) 및 논문 간의 분산(3단계)을 설명합니다. 우리는 여전히 참가자 샘플이 실험 수준에서만 겹쳤기 때문에 실험 수준에서 클러스터를 정의하여 효과 크기 추정에 대한 클러스터-강건 표준 오차, 신뢰 구간 및 통계적 검정을 계산했습니다.

# Discussion

**Performance loses from Human-AI collaboration**
인간-AI 그룹은 인간 단독 또는 AI 단독보다 성능이 좋지 않았습니다. 이 결과는 인간-AI 협업에 대한 질적 문헌 검토를 보완하며, 이는 인간과 인공 지능을 통합할 때 발생하는 놀라운 어려움 중 일부를 강조합니다. 예를 들어, 사람들은 종종 AI 시스템에 너무 많이 의존("과잉 의존")하여 추가 정보를 찾고 처리하지 않고도 AI의 제안을 강력한 지침으로 사용합니다. 그러나 때로는 인간이 자동화에 대한 부정적인 태도 때문에 AI를 너무 적게 의존("과소 의존")하여 AI의 제안을 무시합니다.

**Moderating effect(조절 효과) of task type**
인간-AI 협업의 효과에 영향을 미치는 요인에 대한 추가 분석도 수행했습니다. 과제 유형이 인간-AI 시스템의 시너지를 크게 조절하여 의사 결정 과제는 성과 손실과 관련되고 생성 과제는 성과 향상과 관련된다는 것을 발견했습니다

**Moderating Effect of Relative Human/AI Performance**
인간이 AI보다 단독으로 성능이 뛰어날 때, 인간-AI 시스템에서 성능 향상이 발생했습니다. 이러한 발견은 인간-AI 성능이 인간 단독과 AI 단독의 단순 평균으로 설명될 수 없다는 것을 보여줍니다

**Surprisingly Insignificant Moderators**
설명의 존재 여부, AI 출력의 신뢰도 포함 여부, 평가된 참가자 유형과 같은 다른 조절 변수도 조사했습니다. 이러한 요소들은 최근 몇 년 동안 많은 주목을 받아왔습니다. 우리 결과에 따르면, 300개 이상의 효과 크기에서 평균적으로 이러한 요소들이 인간-AI 협업의 효과에 영향을 미치지 않음을 발견하였다.

## Limitations

첫째, 저희의 정량적 결과는 체계적인 문헌 검토를 통해 수집한 연구들의 부분집합에 적용됩니다. 둘째, 저희는 참가자 간의 분산 함수로 효과 크기에 가중치를 부여하므로, 측정에서 이러한 다른 변동 원인을 고려하지 않습니다. 셋째, 저희는 출판 편향의 증거를 찾지 못했지만, 그것이 존재할 가능성이 있으며, 넷째, 연구자들이 연구하기로 선택한 과업, 프로세스 및 피험자 풀에만 적용되며, 연구 주제 선택 편향이 작용할 수 있습니다. 다섯째, 저희 분석의 품질은 저희가 종합한 연구의 품질에 달려 있습니다. 마지막으로, 저희는 분석에서 효과 크기 간의 높은 수준의 이질성을 발견합니다.

## A roadmap for future work: Finding Human-AI synergy

주요 결과는 평균적으로 인간과 AI를 결합하면 성능 손실이 발생한다는 것을 시사하지만, 이것이 인간과 AI를 결합하는 것이 나쁜 생각이라는 의미는 아니라고 생각합니다. 오히려, 이는 향후 연구가 인간과 AI를 통합하는 효과적인 프로세스를 찾는 데 더 집중해야 함을 의미한다고 생각합니다.  비교 가능성 및 연구 통합을 더욱 촉진하기 위해, 우리는 이 분야가 특히 human-AI 협업 실험을 위한 표준화되고 개방된 보고 리포지토리를 구축하도록 장려합니다.
